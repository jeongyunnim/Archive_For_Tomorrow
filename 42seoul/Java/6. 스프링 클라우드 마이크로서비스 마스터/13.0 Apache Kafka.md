---
날짜: 2024-09-05
넘버: 
태그: 프로그래밍
저자: Eazy Bytes
출처: https://www.udemy.com/course/master-microservices-with-springboot-docker-kubernetes-korean/
aliases:
---
### 날짜:  2024-09-05 23:20

### 태그: #프로그래밍 #자바 #스프링

>[!메모]
>

### 원문
---
# Apache Kafka
## Kafka vs RabbitMQ
- 둘 모두 널리 사용되는 메시징 시스템이다.
- 하지만 **아키텍쳐 설계 방식**과 **use case**가 다르다.
### Design
#### Kafka
- distributed event streaming(분산형 이벤트 스트리밍) 플랫폼 이다.
- 대용량의 데이터를 처리할 수 있도록 설계되었다.
#### RabbitMQ
- 복잡한 라우팅 요구사항을 충족하기 위해 설계되었다.
### Data retention
: 데이터 보존 - 메시지나 이벤트 세부 정보를 메시지 브로커에게 전달할 때 데이터를 저장하는 방식
#### Kafka
- 모든 데이터를 디스크에 저장한다.
	- 원하는 만큼의 데이터를 장기간 저장하거나 유지할 수 있다.
#### RabbitMQ
- 모든 데이터를 메모리 내부에 저장한다.
	- 메모리 내부에 저장하기 때문에 짧은 지연 시간을 필요로 하는 애플리케이션의 경우 더 적합하다.
### Performace
: 성능 - 데이터 보존 후의 성능
#### Kafka
- 대량의 데이터를 처리해야 하는 경우 일반적으로 RabbitMQ보다 빠르다.
#### RabbitMQ
- 복잡한 라우팅 요구사항이 필요한 경우 Kafka 보다 더 나은 성능을 보일 수 있다.
### Scalability
: 확장성
#### Kafka
- 확장성이 뛰어나다.
	- Kafka 클러스터에 수평적으로 Kafka 브로커를 추가할 수 있다.
	- 처리하고자 하는 데이터의 양이나 클러스터 내부의 브로커 수에 제한이 없다.
#### RabbitMQ
- 비교적 확장성이 제한적이다.
	- 어느 정도까지 확장할 수 있는지에 대한 제한 사항이 있다.
### 어느 것을 선택해야 하는가?
- 대용량 데이터를 처리할 수 있는 고성능 메시징 시스템을 원한다면 **Kafka**
- 복잡한 라우팅 요구사항이 있는 메시징 시스템을 원한다면 **RabbitMQ**
	- RabbitMQ는 비교적 유지보수가 매우 쉽기 때문에 작은 양의 데이터를 처리가 예상된다면 rabbitmq를 사용하는 것이 좋다.
## Apache Kafka 소개
### 일상 예제와의 비교
- player(Receiver)를 통해 소스(CD, 안테나, 저장매체)를 읽고 모니터와 스피커로 출력한다.
	- 데이터를 읽으면 리시버에 입력(스트리밍)한다.
![[Pasted image 20240906171137.png]]
- 카프카는 Receiver처럼 Producer와 Consumer 사이에서 브로커 역할을 한다.
### Apache Kafka란?
- 대규모 데이터를 실시간으로 처리할 수 있도록 설계되었다.
	- 데이터 스트리밍 이외에도 높은 처리량, fault tolerant, 확장 가능한 데이터 처리 등이 가능하다.
- 주로 실시간 스트리밍 데이터 파이프라인과 data stream을 사용하는 애플리케이션을 구축하는데 사용된다.
	- JSON, XML, Log 등 어떤 데이터 형식도 지속적으로 전송할 수 있다.
	- Consumer는 카프카로부터 데이터를 전달받아 처리한다.
## Apache Kafka의 구성 요소
![[Pasted image 20240906172512.png]]
### Producer
- 이벤트 스트리밍 플랫폼에서 가장 중요한 요소는 Producer이다.
- 데이터를 생성하거나 이벤트를 생성한다.
	- 지속적으로 Kafka 클러스터로 push 한다.
- 애플리케이션 내부에 필요한만큼 둘 수 있다.
### Cluster
- 원하는 결과물을 생성하기 위해 함께 동작하는 서버(브로커)의 집합
### Broker
- Producer로부터 데이터를 받아 소비자에게 전송하는 서버
	- 클러스터 내부의 서버
- **최소한 2개의 다른 브로커에 메시지를 복제할 수 있도록 3개 이상을 두는 것을 권장한다.**
	- 브로커 서버는 물리적 위치를 분리할 수 있다.
- 브로커 내부에는 토픽이 있다.
	- 브로커는 토픽을 여러 개 가질 수 있다.
### Topic
- rabbitmq의 Exchange와 비슷한 역할을 한다.
- Producer는 Topic과 연결하여 메시지를 전송한다.
- 시나리오에 따라 여러 개의 토픽을 가질 수 있다.
	- 결제, 환불 등
	- 특정 토픽에 대한 프로듀서를 구성할 수 있다.
- 프로듀서에서 이벤트가 발생하면 메시지가 토픽으로 push 된다.
	- 하지만 토픽은 메시지를 저장하지 않는다.
- 토픽 내부에 여러가지 파티션이 있다.
### Partition
- 하나의 브로커 안에 토픽과 관련된 모든 데이터를 저장하는 것은 바람직하지 않다.
- 여러 개의 브로커에 대량의 데이터를 분산하여 저장하려고 한다면 같은 토픽이지만 서로 다른 파티션이 필요하기 때문에 불가능하다.
	- Accounts 서비스에서 새 계정이 생성될 때마다 사용자에게 메시지를 전송한다고 하자. 수백만의 고객이 있을 때 이 수백만의 고객의 모든 메시지, 데이터를 특정 토픽이나 특정 브로커로 보내는 것은 권장되지 않는다.
	- 모든 데이터를 하나의 브로커에 저장할 수 없을 수도 있다.
- 이 문제를 극복하고자 파티션이라는 개념을 도입했다.
	- 서울 고객에게 보내는 모든 통신은 `P0`(partition-0) 으로 보내고, 부산은 P1 등 분리하여 보낸다.
	- 이렇게 하면 비즈니스 시나리오에 따라 이벤트를 특정 토픽의 각 파티션으로 분리할 수 있으며, 클러스터에 브로커를 더 추가할 수 있으므로 **데이터를 유연하게 저장할 수 있다**.
- 파티션에 저장하려는 메시지에 Offset ID를 부여한다.
### Offset
- offset의 역할은 Consumer가 특정 메시지를 식별할 수 있는 유연성을 제공하기 위함이다.
- 파티션이 구분되어 있기 때문에 메시지의 offset이 같은 건 문제가 없다.
	- `Topic`, `Partition`, `Offset ID` 조합은 Kafka 내부에서 유일한 값이 될 것이다.
- 파티션의 도움을 받아 토픽 안에 메시지를 저장하고 오프셋 ID를 할당 하면 Consumer들이 사용할 준비가 된 것이다.
### Consumer
- 카프카 토픽으로부터 메시지를 읽는 주체이다.
- 하나 이상의 토픽을 subscribe 하고, 토픽 내부의 파티션으로부터 메시지를 읽어와 소비한다.
- 여러 Consumer를 하나의 그룹으로 묶을 수 있다.
### Consumer Group
- 특정한 토픽내에서 데이터를 처리하려고 하는 Consumer들을 하나의 그룹으로 묶을 수 있다.
- `통신 전송`이라는 토픽의 메시지를 처리하는 Consumer들을 그룹화 한다.
	- `통신 전송` 토픽의 모든 메시지는 Consumer Group에 의해 처리된다.
- 그룹을 설정하여 메시지를 병렬로 처리할 수 있다.
	- Consumer1은 파티션0에서 메시지를 처리하고 Consumer2는 파티션1에서 메시지를 처리하도록 할 수 있다.
### Replication
: 복제
- **fault tolerance**(내결함성)을 보장하기 위해 여러 브로커에 메시지를 복제하여 저장한다.
- 데이터가 여러 위치(브로커)에 저장되므로 장애 조치 및 고가용성에 대비할 수 있다.
### Stream
- Kafka에서 스트림 처리를 할 수 있도록 하는 클라이언트 라이브러리이다.
- 어떤 애플리케이션에서도 실시간으로 데이터를 생성하여 Kafka 서버로 전송할 수 있고 데이터를 수신하여 처리할 수 있다.
## Producer 와 Consumer 측면에서 살펴보기
### Producer 측면
#### 1. Producer 설정
- 애플리케이션 내에서 생산자를 구성하기.
	- Kafka 브로커의 endpoint URL
	- 메시지 serialize 형식
	- 데이터 전송 시 압축 여부 
	- 데이터 일괄 처리 등
#### 2. 토픽 설정
- Producer가 메시지를 전송할 토픽 설정하기
	- 카프카에 메시지를 전송할 때 데이터를 스트리밍할 토픽을 설정한다.
	- 브로커 구성에 해당 토픽이 없는 경우 토픽이 동적으로 생성될 수 있다.
#### 3. 메시지 생산
- Kafka 클라이언트 라이브러리 API를 이용하여 메시지를 전송할 수 있다.
	- producer는 target 토픽이 무엇인지, Kafka 브로커로 보내려는 serialized된 메시지가 무엇인지 지정해야 한다.
	- 필요한 경우 메시지를 Kafka에 저장할 때 고려할 Partition key를 제공할 수도 있다.
#### 4. 파티션 할당
- Kafka 브로커가 메시지를 수신하면 카프카는 메시지를 파티션 중 하나에 할당한다.
	- 파티션 키가 제공된 경우 파티션 키를 이용하여 해당 파티션에 저장할 것이다.
	- 파티션 키가 제공되지 않은경우 Round robin 또는 hashing 알고리즘 같은 접근방식을 이용하여 여러 파티션에 분산한다.
#### 5. 메시지 라우팅 및 오프셋 할당
- 파티션이 결정되었다면 메시지에 offset을 할당한다.
- 메시지에 offset을 할당하고 식별한 파티션에 메시지를 추가한다.
#### 6. 메시지 복제
- 복제를 활성화한 경우 사용자의 설정에 따라 다른 브로커에 복제를 수행한다.
#### 7. Acknowledgement 와 에러 처리
- Producer에게 acknowledgment를 제공한다.
	- 설정에 따라 복제의 완료 시에 ack를 받거나 leader 파티션에 메시지 저장 시에 ack를 받도록 할 수 있다.
- 에러가 발생한 경우 Producer 비즈니스 로직에서 처리해야 한다.
- 설정에 따라 여러 번 재시도 할 수 있다.
### Consumer 측면
#### 1. Consumer 그룹과 토픽 구독
- Consumer는 group에 할당 되고 각 소비자는 카프카 브로커 내부에서 토픽을 구독해야 한다.
#### 2. 파티션 할당
- 카프카는 구독한 토픽의 파티션을 소비자 그룹 내에서 사용 가능한 소비자에게 할당한다.
- 각 파티션은 그룹에서 **하나의 소비자**만 사용할 수 있다.
	- 이렇게 하면 소비자 간 파티션을 균형있게 분배할 수 있고 병렬로 처리할 수 있다.
#### 3. Offset management
- 오프셋은 소비자가 수행해야 한다.
- 사용하려는 각 파티션에 대한 오프셋의 세부 정보를 관리해야 한다.
	- 아직 처리한 메시지가 없는 경우 offset은 null이 되고, 진행 상황을 추적하기 위해 오프셋을 업데이트 해야 한다.
#### 4. Fetch Request
- 카프카 브로커에 Fetch 요청을 보낸다.
- 포함하는 정보
	- 토픽
	- 파티션
	- 도달하려고 하는 오프셋 번호
	- 가져오려고 하는 메시지 수
		- rabbitmq와 달리 한 번에 여러 메시지를 받아올 수 있다.
#### 5. Message Fetching
- 카프카 브로커가 요청을 받으면 해당 파티션 로그에서 요청된 메시지를 검색하여 소비자에게 전송한다.
- 포함하는 정보
	- 메시지
	- 관련 오프셋
	- 메타데이터
#### 6. 메시지 처리
- Consumer가 메시지를 받으면 비즈니스 로직에 따라 메시지를 처리한다.
	- 메시지 변환, 집계, 계산 등
#### 7. Offset 커밋
- 처리가 완료된 경우 Consumer는 카프카 브로커에게 처리한 오프셋 번호를 커밋한다.
	- 소비자의 진행상황이 카프카 브로커 내부에 유지된다.
	- 장애가 발생하거나 재시작을 할 경우 처리된 오프셋 이후부터 진행을 재개할 수 있다.
#### -> 4번 ~ 7번 반복.
## 카프카 설치
```sh
```

---
### 생각(파생된 질문/생각)

### 출처
- [유데미 - Java, Spring Boot, Spring Cloud, Docker, Kubernetes, Helm, 마이크로서비스 보안](https://www.udemy.com/course/master-microservices-with-springboot-docker-kubernetes-korean/)

### 연결 문서 (연결 이유)
